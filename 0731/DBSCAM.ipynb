{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab9f031-f0ca-4899-ac54-f4d892ec85eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # DBSCAN\n",
    "\n",
    "# ## DBSCAN 개요\n",
    "# - DBSCAN : Density Based Spatial Clustering of Applications with Noise\n",
    "# - 밀도 기반의 군집화 알고리즘\n",
    "#     - 특정 공간 내에 데이터 밀도 차이를 기반\n",
    "# - 데이터의 분포가 기하학적으로 복잡한 데이터 세트에도 효과적인 군집화 가능\n",
    "# - 복잡한 기하학적 분포도를 갖는 데이터 세트에 대해서도 군집화 가능\n",
    "\n",
    "# ![image.png](attachment:image.png)\n",
    "\n",
    "# ### DBSCAN을 구성하는 두 가지 파라미터\n",
    "# - Epsilon : 개별 데이터를 중심으로 입실론 반경을 가지는 원형의 영역\n",
    "# - min points : 개별 데이터의 입실론 주변 영역에 포함되는 타 데이터의 개수\n",
    "\n",
    "# **데이터 포인트 구분**\n",
    "# \n",
    "# : 입실론 주변 영역 내 포함되는 최소 데이터 개수를 충족시키는 기준에 따라 구분\n",
    "# - 핵심 포인트(core point) \n",
    "#     - 주변 영역 내에 최소 데이터 개수 이상의 타 데이터를 가지고 있을 경우\n",
    "# - 이웃 포인트(neighbor point)\n",
    "#     - 주변 영역 내에 위치한 타 데이터\n",
    "# - 경계 포인트(border point)\n",
    "#     - 주변 영역 내에 최소 데이터 개수 이상의 이웃 포인터를 가지고 있지 않지만 핵심 포인트를 이웃 포인터로 가지고 있는 데이터\n",
    "# - 잡음 포인트(noise point)\n",
    "#     - 최소 데이터 개수 이상의 이웃 포인터를 가지고 있지 않으며, 핵심 포인트도 이웃 포인트도 가지고 있지 않는 데이터\n",
    "# \n",
    "\n",
    "# ### DBSCAN 군집화 과정(사례)\n",
    "# : 최소데이터 개수는 5인 경우\n",
    "# \n",
    "# 1. p1~p12 까지 12개 데이터 세트\n",
    "# ![image.png](attachment:image.png)\n",
    "# \n",
    "# \n",
    "# 2. **p1** 데이터를 기준으로 입실론 반경 내에 포함된 데이터가 7개(자신p1, p2, p6, p7, p8, p9, p11)로 최소 데이터 5개 이상을 만족하므로 p1은 **`핵심 포인트`** 이다\n",
    "# ![image-2.png](attachment:image-2.png)\n",
    "# \n",
    "# \n",
    "# 3. **p2** 데이터 포인트는 반경 내에 6개 데이터(p2, 이웃데이터 p1, p3, p4, p9, p10)를 가지고 있으므로 **`핵심 포인트`** 이다\n",
    "# ![image-3.png](attachment:image-3.png)\n",
    "# \n",
    "# \n",
    "# 4. 핵심포인트 p1의 이웃 데이터 포인트 p2 역시 핵심포인트일 경우 p1에서 p2로 **연결해 직접 접근이 가능** 하다.\n",
    "# ![image-4.png](attachment:image-4.png)\n",
    "# \n",
    "# \n",
    "# 5. 특정 핵심 포인트에서 직접 접근이 가능한 다른 핵심포인트를 서로 연결하면서 군집화를 구성한다. 이러한 방식으로 점차적으로 군집(cluster) 영역을 확장해 나간다(=> **`DBSCAN 군집화 방식`** )\n",
    "# ![image-5.png](attachment:image-5.png)\n",
    "# \n",
    "# \n",
    "# 6. **p3** 데이터의 경우 반경 내에 포함되는 이웃 데이터는 p2, p4로 군집으로 분류할 수 있는 핵심 포인트가 되지 못한다. 그러나 이웃 데이터 중 핵심 포인트 p2를 가지고 있으므로 **`경계 포인트`** 가 되며 군집의 외곽을 형성한다.\n",
    "# ![image-6.png](attachment:image-6.png)\n",
    "# \n",
    "# \n",
    "# \n",
    "# 7. **p5**와 같이 반경 내에 최소 데이터를 가지고 있지 않고 핵심 포인트를 이웃 포인트로 가지고 있지 않는 데이터는 **`잡음 포인터`** 이다. \n",
    "\n",
    "# ### 사이킷런에서 DBSCAN 클래스 `DBSCAN`\n",
    "sklearn.cluster.DBSCAN(X, eps=0.5, *, min_samples=5, metric='minkowski', metric_params=None, algorithm='auto', leaf_size=30, p=2, sample_weight=None, n_jobs=None)[source]\n",
    "# DBSCAN 초기화 파라미터\n",
    "# - eps : 입실론 주변 영역의 반경\n",
    "# - min_samples : 핵심포인트가 되기 위한 입실론 주변 영역 내에 포함될 데이터의 최소 개수(자신의 데이터 포함)\n",
    "\n",
    "# ### DBSCAN 적용하기 – 붓꽃 데이터 셋\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "iris = load_iris()\n",
    "feature_names = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "\n",
    "# 보다 편리한 데이타 Handling을 위해 DataFrame으로 변환\n",
    "irisDF = pd.DataFrame(data=iris.data, columns=feature_names)\n",
    "irisDF['target'] = iris.target\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.6, min_samples=8, metric='euclidean')\n",
    "dbscan_labels = dbscan.fit_predict(iris.data)\n",
    "\n",
    "irisDF['dbscan_cluster'] = dbscan_labels\n",
    "irisDF['target'] = iris.target\n",
    "\n",
    "iris_result = irisDF.groupby(['target'])['dbscan_cluster'].value_counts()\n",
    "print(iris_result)\n",
    "\n",
    "\n",
    "# => DBSCAN 군집화 결과 0과 1 두 개의 군집으로 군집화됨\n",
    "# - 군집레이블 -1은 노이즈에 속하는 군집\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "### 클러스터 결과를 담은 DataFrame과 사이킷런의 Cluster 객체등을 인자로 받아 \n",
    "### 클러스터링 결과를 시각화하는 함수\n",
    "\n",
    "def visualize_cluster_plot(clusterobj, dataframe, label_name, iscenter=True):\n",
    "    if iscenter :\n",
    "        centers = clusterobj.cluster_centers_\n",
    "        \n",
    "    unique_labels = np.unique(dataframe[label_name].values)\n",
    "    markers=['o', 's', '^', 'x', '*']\n",
    "    isNoise=False\n",
    "\n",
    "    for label in unique_labels:\n",
    "        label_cluster = dataframe[dataframe[label_name]==label]\n",
    "        if label == -1:\n",
    "            cluster_legend = 'Noise'\n",
    "            isNoise=True\n",
    "        else :\n",
    "            cluster_legend = 'Cluster '+str(label)\n",
    "        \n",
    "        plt.scatter(x=label_cluster['ftr1'], y=label_cluster['ftr2'], s=70,                    edgecolor='k', marker=markers[label], label=cluster_legend)\n",
    "        \n",
    "        if iscenter:\n",
    "            center_x_y = centers[label]\n",
    "            plt.scatter(x=center_x_y[0], y=center_x_y[1], s=250, color='white',\n",
    "                        alpha=0.9, edgecolor='k', marker=markers[label])\n",
    "            plt.scatter(x=center_x_y[0], y=center_x_y[1], s=70, color='k',                        edgecolor='k', marker='$%d$' % label)\n",
    "    if isNoise:\n",
    "        legend_loc='upper center'\n",
    "    else: legend_loc='upper right'\n",
    "    \n",
    "    plt.legend(loc=legend_loc)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# **PCA를 적용하여 2차원 데이터 세트로 변환 후 DBSCAN 군집화 결과 시각화**\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# 2차원으로 시각화하기 위해 PCA n_componets=2로 피처 데이터 세트 변환\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "pca_transformed = pca.fit_transform(iris.data)\n",
    "# visualize_cluster_2d( ) 함수는 ftr1, ftr2 컬럼을 좌표에 표현하므로 PCA 변환값을 해당 컬럼으로 생성\n",
    "irisDF['ftr1'] = pca_transformed[:,0]\n",
    "irisDF['ftr2'] = pca_transformed[:,1]\n",
    "\n",
    "visualize_cluster_plot(dbscan, irisDF, 'dbscan_cluster', iscenter=False)\n",
    "\n",
    "\n",
    "# **eps를 0.6에서 0.8로 변경 : 노이즈 데이터가 줄어듬**\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.8, min_samples=8, metric='euclidean')\n",
    "dbscan_labels = dbscan.fit_predict(iris.data)\n",
    "\n",
    "irisDF['dbscan_cluster'] = dbscan_labels\n",
    "irisDF['target'] = iris.target\n",
    "\n",
    "iris_result = irisDF.groupby(['target'])['dbscan_cluster'].value_counts()\n",
    "print(iris_result)\n",
    "\n",
    "visualize_cluster_plot(dbscan, irisDF, 'dbscan_cluster', iscenter=False)\n",
    "\n",
    "\n",
    "# => eps를 0.6에서 0.8로 늘리면 noise는 줄어듬\n",
    "\n",
    "# **eps=0.6, min_samples=16일 경우**\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "dbscan = DBSCAN(eps=0.6, min_samples=16, metric='euclidean')\n",
    "dbscan_labels = dbscan.fit_predict(iris.data)\n",
    "\n",
    "irisDF['dbscan_cluster'] = dbscan_labels\n",
    "irisDF['target'] = iris.target\n",
    "\n",
    "iris_result = irisDF.groupby(['target'])['dbscan_cluster'].value_counts()\n",
    "print(iris_result)\n",
    "\n",
    "visualize_cluster_plot(dbscan, irisDF, 'dbscan_cluster', iscenter=False)\n",
    "\n",
    "\n",
    "# => eps는 6이고, min-samples 수를 늘리면 noise가 늘어남\n",
    "\n",
    "# ### DBSCAN 적용하기 – make_circles() 데이터 세트\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "X, y = make_circles(n_samples=1000, shuffle=True, noise=0.05, random_state=0, factor=0.5)\n",
    "clusterDF = pd.DataFrame(data=X, columns=['ftr1', 'ftr2'])\n",
    "clusterDF['target'] = y\n",
    "\n",
    "visualize_cluster_plot(None, clusterDF, 'target', iscenter=False)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "# KMeans로 make_circles( ) 데이터 셋을 클러스터링 수행. \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, max_iter=1000, random_state=0)\n",
    "kmeans_labels = kmeans.fit_predict(X)\n",
    "clusterDF['kmeans_cluster'] = kmeans_labels\n",
    "\n",
    "visualize_cluster_plot(kmeans, clusterDF, 'kmeans_cluster', iscenter=True)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "# GMM으로 make_circles( ) 데이터 셋을 클러스터링 수행. \n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=2, random_state=0)\n",
    "gmm_label = gmm.fit(X).predict(X)\n",
    "clusterDF['gmm_cluster'] = gmm_label\n",
    "\n",
    "visualize_cluster_plot(gmm, clusterDF, 'gmm_cluster', iscenter=False)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "# DBSCAN으로 make_circles( ) 데이터 셋을 클러스터링 수행. \n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=10, metric='euclidean')\n",
    "dbscan_labels = dbscan.fit_predict(X)\n",
    "clusterDF['dbscan_cluster'] = dbscan_labels\n",
    "\n",
    "visualize_cluster_plot(dbscan, clusterDF, 'dbscan_cluster', iscenter=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
